import numpy as np
import datetime
import time
from qiskit import QuantumCircuit, transpile
from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2, SamplerOptions

# ==========================================
# âš”ï¸ 0.25 åè®®ï¼šæ ‡åº¦å¾‹ç»ˆæéªŒè¯ (Scaling Law Verdict)
#    Target: è¯æ˜ P(n) æ”¶æ•›äº e^(-pi * gamma)
# ==========================================

print(f"ğŸš€ [00:00] æ­£åœ¨è¿æ¥ IBM Quantum (Mode: Scaling Scan)...")
try:
    service = QiskitRuntimeService()
except:
    service = QiskitRuntimeService(channel="ibm_quantum")
backend = service.backend("ibm_torino")

# 1. æ ¸å¿ƒç”µè·¯æ„å»ºå™¨ (å¸¦ Gamma å‚æ•°)
def build_scaling_circuit(n_layers, gamma):
    qc = QuantumCircuit(3)
    
    # ã€å…³é”®ã€‘åˆå§‹åŒ–åˆ° |111> (æ¿€å‘æ€) - ä¿æŒä¹‹å‰çš„é€†æµè®¾å®š
    qc.x([0, 1, 2])
    qc.barrier()

    # éå„ç±³æ³µæµ¦å±‚ (Scaling Block)
    for _ in range(n_layers):
        qc.rx(gamma * np.pi, [0, 1, 2])
        qc.cz(0, 1)
        qc.cz(1, 2)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ‰«æ Gammaï¼Œæ‰€ä»¥æ³µæµ¦ç›¸ä¹Ÿè¦å¯¹åº”
        # ä¿æŒ "é€†æµ" æ‰‹æ€§ (-gamma)
        qc.rz(-gamma * np.pi, [0, 1, 2]) 
    
    # é€†å‘å›æº¯ (Time Reversal)
    qc.barrier()
    qc.append(qc.inverse(), [0, 1, 2])
    qc.measure_all()
    return qc

# 2. å®éªŒè®¾è®¡ï¼šä¸‰è·¯å¤§å†›
# Group A (ä¸»çº¿): Gamma = 0.25 (ç†è®ºæé™ ~0.456)
# Group B (å¯¹ç…§): Gamma = 0.20 (ç†è®ºæé™ ~0.533) -> åº”è¯¥æ›´é«˜
# Group C (å¯¹ç…§): Gamma = 0.30 (ç†è®ºæé™ ~0.389) -> åº”è¯¥æ›´ä½

# æ·±åº¦æ‰«æç‚¹ (Layers)
# æˆ‘ä»¬ä¸ä»…è¦çœ‹ç»ˆç‚¹(150)ï¼Œè¿˜è¦çœ‹ä¸­é—´çš„è½¨è¿¹
scan_plan = [
    {'gamma': 0.25, 'depths': [10, 30, 60, 90, 120, 150]}, # ä¸»çº¿ï¼šæå…¶ç»†è‡´
    {'gamma': 0.20, 'depths': [30, 90, 150]},             # å¯¹ç…§1ï¼šåªè¦å…³é”®ç‚¹
    {'gamma': 0.30, 'depths': [30, 90, 150]}              # å¯¹ç…§2ï¼šåªè¦å…³é”®ç‚¹
]

# é…ç½® Sampler (å¿…é¡»å¼€ XY4)
options = SamplerOptions()
options.dynamical_decoupling.enable = True
options.dynamical_decoupling.sequence_type = 'XY4'
options.default_shots = 8000 # é€‚å½“é™ä½ Shot æ•°ä»¥æ¢å–æ›´å¤šæ‰«æç‚¹ï¼Œæ€»è€—æ—¶ç›¸å½“

sampler = SamplerV2(backend, options=options)

# 3. æ‰§è¡Œæ‰«æ
print(f"\nğŸ”¥ğŸ”¥ğŸ”¥ å¯åŠ¨æ ‡åº¦å¾‹æ‰«æ (Total Jobs: {sum(len(p['depths']) for p in scan_plan)}) ğŸ”¥ğŸ”¥ğŸ”¥")
job_records = []

for group in scan_plan:
    g = group['gamma']
    theoretical_limit = np.exp(-np.pi * g)
    print(f"\n   >>> æ­£åœ¨è£…å¡« Gamma = {g} (ç†è®ºæé™: {theoretical_limit:.4f})")
    
    for d in group['depths']:
        # æ„å»ºç”µè·¯
        qc = build_scaling_circuit(n_layers=d, gamma=g)
        transpiled_qc = transpile(qc, backend, optimization_level=1)
        
        # å‘å°„
        job = sampler.run([transpiled_qc])
        jid = job.job_id()
        
        # è®°å½•
        info = f"Gamma={g} | Depth={d} | ID={jid}"
        job_records.append(info)
        print(f"       ğŸš€ Depth {d}: å‘å°„æˆåŠŸ! (ID: {jid})")
        time.sleep(0.5)

# 4. ä¿å­˜æˆ˜æœ
log_filename = "scaling_law_ids.txt"
with open(log_filename, "a") as f:
    f.write(f"\n=== SCALING LAW VERDICT {datetime.datetime.now().isoformat()} ===\n")
    for rec in job_records:
        f.write(f"{rec}\n")

print(f"\nâœ… æ‰«æå®Œæ¯•ï¼æ‰€æœ‰ ID å·²ä¿å­˜ã€‚")
print("ç­‰å¾…æ•°æ®å›æ”¶... è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬è¦ç”»å‡ºé‚£æ¡è®©çƒ­åŠ›å­¦çª’æ¯çš„æ›²çº¿ã€‚")
